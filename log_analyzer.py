from __future__ import annotations
"""log_analyzer_cli.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1o4-kkw3wkly7pluZ0mMNMobI1TfxYbrQ
"""

"""
Tiny Log Analyzer (CLI+)
- Read one or more files (or --stdin)
- Optional keyword and level filters
- Count repeated lines; show top N
- Extract and count IPs
- Optional report output to a file
"""
import argparse
import sys
import re
from pathlib import Path
from collections import Counter
from typing import Iterable, Iterator, Sequence

LEVEL_RE = re.compile(r"\b(ERROR|WARN|WARNING|INFO|DEBUG|CRITICAL)\b", re.IGNORECASE)
IP_RE    = re.compile(r"\b(?:\d{1,3}\.){3}\d{1,3}\b")

def iter_lines(paths: Sequence[Path]) -> Iterator[str]:
    """Yield lines from all files (utf-8), skipping unreadable ones with a warning."""
    for path in paths:
        try:
            with path.open("r", encoding="utf-8", errors="replace") as file:
                for line in file:
                    yield line.rstrip("\n")
        except FileNotFoundError:
            print(f"File not found: {path}", file=sys.stderr)
        except OSError as e:
            print(f"Cannot read {path}: {e}", file=sys.stderr)

def filter_keyword(lines: Iterable[str], keyword: str, ignore_case: bool) -> Iterator[str]:
    if not keyword:
        yield from lines
        return
    keyword_final = keyword
    if ignore_case:
        keyword_final = keyword.lower()
    for line in lines:
        if keyword in line:
            yield line

def filter_level(lines: Iterable[str], level: str | None) -> Iterator[str]:
    if not level:
        yield from lines
        return
    level_upper = level.upper()
    for line in lines:
        m = LEVEL_RE.search(line)
        if m and m.group(1).upper().startswith(level_upper):
            yield line

def count_lines(lines: Iterable[str]) -> Counter[str]:
    c = Counter()
    for line in lines:
        if line.strip():
            c[line] += 1
    return c

def count_ips(lines: Iterable[str]) -> Counter[str]:
    c = Counter()
    for line in lines:
        for ip in IP_RE.findall(line):
            c[ip] += 1
    return c

def format_table(title: str, pairs: Sequence[tuple[str, int]], width: int = 60) -> str:
    result = [f"=== {title} ==="]
    for k, v in pairs:
        left = (k[:width-10] + "...") if len(k) > width - 3 else k
        result.append(f"{left.ljust(width)} {v}")
    return "\n".join(result)

def main(argv: Sequence[str] | None = None) -> int:
    parser = argparse.ArgumentParser(description="Tiny Log Analyzer (CLI+)")
    parser.add_argument("paths", nargs="*", help="Log file paths (accepts globs on most shells)")
    parser.add_argument("--stdin", action="store_true", help="Read from STDIN instead of files")
    parser.add_argument("--keyword", help="Only count lines containing this keyword")
    parser.add_argument("--ignore-case", action="store_true", help="Case-insensitive keyword match")
    parser.add_argument("--level", choices=["ERROR","WARN","WARNING","INFO","DEBUG","CRITICAL"],
                    help="Filter by detected level")
    parser.add_argument("--top", type=int, default=10, help="Show top N results (default: 10)")
    parser.add_argument("--ips", action="store_true", help="Extract and count IPv4 addresses")
    parser.add_argument("--out", type=Path, help="Write report to this file instead of stdout")
    args = parser.parse_args(argv)

    # Collect input lines
    if args.stdin:
        src_lines = (ln.rstrip("\n") for ln in sys.stdin)
    else:
        if not args.paths:
            parser.error("Provide at least one path or use --stdin")
        paths = [Path(p) for p in args.paths]
        src_lines = iter_lines(paths)

    # Apply filters in sequence
    line1 = filter_keyword(src_lines, args.keyword or "", args.ignore_case)
    line2 = filter_level(line1, args.level)

    # Count lines and (optionally) IPs
    line_counts = count_lines(line2)
    top_lines = line_counts.most_common(args.top)

    # For IP counting, we must re-run filters over the source (generators are one-pass).
    # Reconstruct pipeline:

    if args.stdin:
        # If reading from stdin, we already consumed it; so warn and skip IPs
        ip_counts = Counter()
        if args.ips:
            print("[WARN] --ips ignored with stdin (stream already consumed). Pipe twice if needed.", file=sys.stderr)
    else:
        paths = [Path(path) for path in args.paths]
        keyword_filter = filter_keyword(iter_lines(paths), args.keyword or "", args.ignore_case)
        line_ip = filter_level(keyword_filter, args.level)
        ip_counts = count_ips(line_ip) if args.ips else Counter()

    # Build report text
    report_parts = []
    report_parts.append(format_table("Top Lines", top_lines))
    if args.ips:
        report_parts.append(format_table("Top IPs", ip_counts.most_common(args.top)))
    report = "\n".join(report_parts) + "\n"

    # Output
    if args.out:
        try:
            args.out.parent.mkdir(parents=True, exist_ok=True)
            args.out.write_text(report, encoding="utf-8")
            print(f"[OK] Report written -> {args.out}", file=sys.stderr)
        except OSError as e:
            print(f"[ERROR] Cannot write to {args.out}: {e}", file=sys.stderr)
            print(report)
    else:
        print(report)
    return 0

if __name__ == "__main__":
    raise SystemExit(main())